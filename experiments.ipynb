{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NotV2BEjb0fQ",
        "trpiKJAYch_w",
        "kOlpYCPncr4p"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installs, Imports and Loading the Model"
      ],
      "metadata": {
        "id": "NotV2BEjb0fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.6 transformers"
      ],
      "metadata": {
        "id": "YHkkK2wQalyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from typing import Callable, List, Optional, Union\n",
        "import inspect\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DqZuOI_M2r9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16).to(\"cuda\")"
      ],
      "metadata": {
        "id": "9o_FUSfxzlCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir imgs"
      ],
      "metadata": {
        "id": "ife7PzEqcYGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir imgs/homonym_duplication imgs/meaning_edit imgs/meaning_sum"
      ],
      "metadata": {
        "id": "xiDRPCNUONCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Definitions"
      ],
      "metadata": {
        "id": "o7auMmAqcIF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Utility Functions"
      ],
      "metadata": {
        "id": "QFV9zoS9Wzl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def project(a, b):\n",
        "    bb_dotprod = torch.dot(b,b)\n",
        "    ab_dotprod = torch.dot(a,b)\n",
        "    if bb_dotprod != 0:\n",
        "        coeff = (ab_dotprod/bb_dotprod)\n",
        "    else:\n",
        "        coeff = 0\n",
        "    return coeff * b"
      ],
      "metadata": {
        "id": "i4tIXF3HcLRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def w_b(w, b):\n",
        "    v_b = torch.zeros((768)).type(torch.HalfTensor).cuda()\n",
        "    for j in range(len(b)):\n",
        "        v_b += torch.dot(w,b[j]) * b[j]\n",
        "    return v_b\n",
        "\n",
        "def normal(v):\n",
        "    return (1/torch.sqrt(torch.dot(v,v))) * v"
      ],
      "metadata": {
        "id": "SliJDCy1cPdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(v):\n",
        "  return torch.sqrt(torch.dot(v,v))"
      ],
      "metadata": {
        "id": "phlBrxvRcRBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(a,b):\n",
        "  return torch.dot(a,b)/(torch.sqrt(torch.dot(a,a))*torch.sqrt(torch.dot(b,b)))"
      ],
      "metadata": {
        "id": "h3ZVAQTGcTFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Images\n",
        "\n",
        "Edited version of the ```StableDiffusionPipeline```'s ```__call__()``` function that enables giving the text embedding directly as input.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wxtgZ4LtW3Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images(text_embeddings, pipe, img_name,prompt=None, negative_prompt=None,num_images_per_prompt=3):\n",
        "    height = 512\n",
        "    width = 512\n",
        "    num_inference_steps = 50\n",
        "    guidance_scale = 7.5\n",
        "    eta = 0.0\n",
        "    generator = None\n",
        "    latents = None\n",
        "    output_type=\"pil\"\n",
        "    return_dict = True\n",
        "    callback= None\n",
        "    callback_steps= 1\n",
        "    batch_size =1\n",
        "    with torch.no_grad():\n",
        "\n",
        "        bs_embed, seq_len, _ = text_embeddings.shape\n",
        "        text_embeddings = text_embeddings.repeat(1, num_images_per_prompt, 1)\n",
        "        text_embeddings = text_embeddings.view(bs_embed * num_images_per_prompt, seq_len, -1)\n",
        "\n",
        "        do_classifier_free_guidance = guidance_scale > 1.0\n",
        "        if do_classifier_free_guidance:\n",
        "            uncond_tokens: List[str]\n",
        "            if negative_prompt is None:\n",
        "                uncond_tokens = [\"\"]\n",
        "            elif type(prompt) is not type(negative_prompt):\n",
        "                raise TypeError(\n",
        "                    f\"`negative_prompt` should be the same type to `prompt`, but got {type(negative_prompt)} !=\"\n",
        "                    f\" {type(prompt)}.\"\n",
        "                )\n",
        "            elif isinstance(negative_prompt, str):\n",
        "                uncond_tokens = [negative_prompt]\n",
        "            elif batch_size != len(negative_prompt):\n",
        "                raise ValueError(\n",
        "                    f\"`negative_prompt`: {negative_prompt} has batch size {len(negative_prompt)}, but `prompt`:\"\n",
        "                    f\" {prompt} has batch size {batch_size}. Please make sure that passed `negative_prompt` matches\"\n",
        "                    \" the batch size of `prompt`.\"\n",
        "                )\n",
        "            else:\n",
        "                uncond_tokens = negative_prompt\n",
        "\n",
        "            max_length = text_embeddings.shape[1]\n",
        "            uncond_input = pipe.tokenizer(\n",
        "                uncond_tokens,\n",
        "                padding=\"max_length\",\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "            uncond_embeddings = pipe.text_encoder(uncond_input.input_ids.to(pipe.device))[0]\n",
        "\n",
        "            seq_len = uncond_embeddings.shape[1]\n",
        "            uncond_embeddings = uncond_embeddings.repeat(batch_size, num_images_per_prompt, 1)\n",
        "            uncond_embeddings = uncond_embeddings.view(batch_size * num_images_per_prompt, seq_len, -1)\n",
        "\n",
        "            text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "        latents_shape = (batch_size * num_images_per_prompt, pipe.unet.in_channels, height // 8, width // 8)\n",
        "        latents_dtype = text_embeddings.dtype\n",
        "        if latents is None:\n",
        "            if pipe.device.type == \"mps\":\n",
        "                latents = torch.randn(latents_shape, generator=generator, device=\"cpu\", dtype=latents_dtype).to(\n",
        "                    pipe.device\n",
        "                )\n",
        "            else:\n",
        "                latents = torch.randn(latents_shape, generator=generator, device=pipe.device, dtype=latents_dtype)\n",
        "        else:\n",
        "            if latents.shape != latents_shape:\n",
        "                raise ValueError(f\"Unexpected latents shape, got {latents.shape}, expected {latents_shape}\")\n",
        "            latents = latents.to(pipe.device)\n",
        "\n",
        "        pipe.scheduler.set_timesteps(num_inference_steps)\n",
        "\n",
        "        timesteps_tensor = pipe.scheduler.timesteps.to(pipe.device)\n",
        "\n",
        "        latents = latents * pipe.scheduler.init_noise_sigma\n",
        "\n",
        "        accepts_eta = \"eta\" in set(inspect.signature(pipe.scheduler.step).parameters.keys())\n",
        "        extra_step_kwargs = {}\n",
        "        if accepts_eta:\n",
        "            extra_step_kwargs[\"eta\"] = eta\n",
        "\n",
        "        for i, t in enumerate(pipe.progress_bar(timesteps_tensor)):\n",
        "            latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
        "            latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "            noise_pred = pipe.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
        "\n",
        "            if do_classifier_free_guidance:\n",
        "                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "                noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "            latents = pipe.scheduler.step(noise_pred, t, latents, **extra_step_kwargs).prev_sample\n",
        "\n",
        "            if callback is not None and i % callback_steps == 0:\n",
        "                callback(i, t, latents)\n",
        "\n",
        "        latents = 1 / 0.18215 * latents\n",
        "        image = pipe.vae.decode(latents).sample\n",
        "\n",
        "        image = (image / 2 + 0.5).clamp(0, 1)\n",
        "\n",
        "        image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n",
        "\n",
        "        has_nsfw_concept = None\n",
        "\n",
        "        if output_type == \"pil\":\n",
        "            image = pipe.numpy_to_pil(image)\n",
        "\n",
        "        if not return_dict:\n",
        "            print(\"NSFW\")\n",
        "\n",
        "        out=image\n",
        "\n",
        "        for i in range(len(image)):\n",
        "            image[i].save(\"imgs/\"+img_name + \"_\"+str(i)+\".png\")"
      ],
      "metadata": {
        "id": "d12Oz8wN3HI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Encodings"
      ],
      "metadata": {
        "id": "hC9mR1nBXQG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_prompt_embed(prompt_1, pipe):\n",
        "    text_inputs = pipe.tokenizer(\n",
        "        prompt_1,\n",
        "        padding=\"max_length\",\n",
        "        max_length=pipe.tokenizer.model_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    text_input_ids = text_inputs.input_ids\n",
        "\n",
        "    text_embeddings_1 = pipe.text_encoder(text_input_ids.to(pipe.device))[0]\n",
        "    \n",
        "    return text_embeddings_1"
      ],
      "metadata": {
        "id": "oPCUyBIE3EWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_embedding(prompt_1, prompt_2, pipe, weights=[0.5,0.5]):\n",
        "    text_inputs = pipe.tokenizer(\n",
        "        prompt_1,\n",
        "        padding=\"max_length\",\n",
        "        max_length=pipe.tokenizer.model_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    text_input_ids = text_inputs.input_ids\n",
        "\n",
        "    text_embeddings_1 = pipe.text_encoder(text_input_ids.to(pipe.device))[0]\n",
        "\n",
        "    text_inputs = pipe.tokenizer(\n",
        "        prompt_2,\n",
        "        padding=\"max_length\",\n",
        "        max_length=pipe.tokenizer.model_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    text_input_ids = text_inputs.input_ids\n",
        "\n",
        "    text_embeddings_2 = pipe.text_encoder(text_input_ids.to(pipe.device))[0]\n",
        "\n",
        "    text_embeddings = (weights[0] * text_embeddings_1) + (weights[1]*text_embeddings_2)\n",
        "\n",
        "    return text_embeddings"
      ],
      "metadata": {
        "id": "_4g_uPS23A01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate All Images for Experiments on Summing Encodings"
      ],
      "metadata": {
        "id": "D34U3V7bXTkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concept_sum(concept_1, concept_2, pipe, filename, weights=[0.5,0.5]):\n",
        "    for i in range(10):\n",
        "        get_images(sum_embedding(concept_1,concept_2, pipe,weights), pipe, filename+\"_sum_\"+str(i))\n",
        "    for i in range(10):\n",
        "        get_images(one_prompt_embed(concept_1, pipe), pipe, filename+\"_1_\"+str(i))\n",
        "        get_images(one_prompt_embed(concept_2, pipe), pipe, filename+\"_2_\"+str(i))"
      ],
      "metadata": {
        "id": "byk9Hk8w0vJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Meaning Directions"
      ],
      "metadata": {
        "id": "F7UrlQtXXa_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def diff_svd(vectors_m, vectors_n, n, model_dim=768):\n",
        "    mus = [torch.zeros((model_dim)).cuda() for i in range(n)]\n",
        "\n",
        "    for i in range(n):\n",
        "        mus[i] = (1/2)*(vectors_m[i]+vectors_n[i])\n",
        "\n",
        "    subspace = torch.zeros((model_dim,model_dim)).cuda()\n",
        "\n",
        "    for i in range(n):\n",
        "        subspace += (1/2)*torch.outer(vectors_m[i] - mus[i],vectors_m[i]- mus[i])\n",
        "        subspace += (1/2)*torch.outer(vectors_n[i] - mus[i],vectors_n[i]- mus[i])\n",
        "    u_m, s_m, v = np.linalg.svd(subspace.detach().cpu(), full_matrices=True)\n",
        "    return torch.tensor(u_m).type(torch.HalfTensor).cuda(), s_m\n",
        "\n",
        "def find_vectors(w, sentences_1, sentences_2, sentences_amb, pipe, min_dim=10, threshold=0.99, model_dim=768):\n",
        "    n = len(sentences_1)\n",
        "    vectors_1 = []\n",
        "    vectors_2 = []\n",
        "    vectors_amb = []\n",
        "    for i in range(n):\n",
        "        full_vec_1 = one_prompt_embed(sentences_1[i], pipe)\n",
        "        w_idx = sentences_1[i].split(\" \").index(w) + 1\n",
        "        vec_1 = full_vec_1[:,w_idx,:].squeeze(0)\n",
        "        vectors_1.append(vec_1)\n",
        "\n",
        "        full_vec_2 = one_prompt_embed(sentences_2[i], pipe)\n",
        "        w_idx = sentences_2[i].split(\" \").index(w) + 1\n",
        "        vec_2 = full_vec_2[:,w_idx,:].squeeze(0)\n",
        "        vectors_2.append(vec_2)\n",
        "\n",
        "        full_vec_amb = one_prompt_embed(sentences_amb[i], pipe)\n",
        "        w_idx = sentences_amb[i].split(\" \").index(w) + 1\n",
        "        vec_amb = full_vec_amb[:,w_idx,:].squeeze(0)\n",
        "        vectors_amb.append(vec_amb)\n",
        "\n",
        "    u_1, s_1 = diff_svd(vectors_1, vectors_amb, n, model_dim)\n",
        "    u_2, s_2 = diff_svd(vectors_2, vectors_amb, n, model_dim)\n",
        "\n",
        "    dim = 0\n",
        "    while sum(s_1[:dim])/sum(s_1) < threshold or sum(s_2[:dim])/sum(s_2) < threshold or dim < min_dim:\n",
        "        dim += 1\n",
        "    u_b_1 = [u_1[:,j] for j in range(dim)]\n",
        "    u_b_2 = [u_2[:,j] for j in range(dim)]\n",
        "\n",
        "    diff_1 = [normal(w_b(vectors_1[i], u_b_1)) for i in range(n)]\n",
        "    diff_2 = [normal(w_b(vectors_2[i], u_b_2)) for i in range(n)]\n",
        "    diff_amb_1 = [normal(w_b(vectors_amb[i], u_b_1)) for i in range(n)]\n",
        "    diff_amb_2 = [normal(w_b(vectors_amb[i], u_b_2)) for i in range(n)]\n",
        "\n",
        "    v_1 = torch.zeros((model_dim)).type(torch.HalfTensor).cuda()\n",
        "    v_2 = torch.zeros((model_dim)).type(torch.HalfTensor).cuda()\n",
        "    for i in range(dim):\n",
        "        v_1 += sum([torch.dot(diff_1[j]  , u_b_1[i]) for j in range(n)])/n * u_b_1[i] \n",
        "        v_2 += sum([torch.dot(diff_2[j] , u_b_2[i]) for j in range(n)])/n * u_b_2[i]\n",
        "\n",
        "    for i in range(n):\n",
        "        v_1 = v_1 - project(v_1, normal(vectors_2[i]))\n",
        "        v_2 = v_2 - project(v_2, normal(vectors_1[i]))\n",
        "\n",
        "    norm_v_1 = norm(v_1)\n",
        "    v_1 = normal(v_1)\n",
        "\n",
        "    norm_v_2 = norm(v_2)\n",
        "    v_2 = normal(v_2)\n",
        "    for i in range(n):\n",
        "        proj_1 = vectors_1[i]\n",
        "        proj_2 = vectors_2[i]\n",
        "        proj_amb = vectors_amb[i]\n",
        "    return max([torch.dot(vectors_1[j] , v_1) for j in range(n)]) *v_1, max([torch.dot(vectors_2[j] , v_2) for j in range(n)]) *v_2"
      ],
      "metadata": {
        "id": "XWMTr7MnbtYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Editing Embedding"
      ],
      "metadata": {
        "id": "SoVdyJ6-Xd7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_embed(orig_embed, meaning_1, meaning_2):\n",
        "    u = [normal(meaning_1),normal(meaning_2 - project(meaning_2, normal(meaning_1)))]\n",
        "    # pushing ambiguous towards meaning_2\n",
        "    orig_embed = orig_embed  - w_b(orig_embed, u) + norm(meaning_2)*normal(meaning_2 -project(meaning_2, meaning_1)) \n",
        "    return orig_embed"
      ],
      "metadata": {
        "id": "xZhNklLctB7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate All Images for Sense Editing Experiments"
      ],
      "metadata": {
        "id": "JNawHZp0Xkpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_prompts(word, prompt_dict, sentences_1, sentences_2, sentences_amb, pipe, neg_prompt=\"\", repeat=5):\n",
        "    v_1, v_2 = find_vectors(word, sentences_1, sentences_2, sentences_amb, pipe, threshold=0.95,min_dim=3)\n",
        "    for prompt, filename in prompt_dict.items():\n",
        "        orig_prompt = prompt\n",
        "        orig_embed = one_prompt_embed(orig_prompt,pipe)\n",
        "        idx = orig_prompt.split(\" \").index(word) + 1\n",
        "\n",
        "        embed_1 = orig_embed.detach().clone()\n",
        "        embed_1[:,idx,:] = edit_embed(embed_1[:,idx,:].squeeze(0).clone(), v_2, v_1).clone()\n",
        "\n",
        "        embed_2 = orig_embed.detach().clone()\n",
        "        embed_2[:,idx,:] = edit_embed(embed_2[:,idx,:].squeeze(0).clone(), v_1, v_2).clone()\n",
        "        \n",
        "        for i in range(repeat):\n",
        "            get_images(embed_1, pipe, filename + \"sense_1_\" + str(i))\n",
        "            get_images(embed_2, pipe, filename + \"sense_2_\" + str(i))\n",
        "            get_images(orig_embed, pipe, filename + \"amb_\" + str(i))\n",
        "        if neg_prompt != \"\":\n",
        "            for i in range(repeat):\n",
        "                get_images(embed_1, pipe, filename + \"sense_1_\" + str(i)+\"_neg\", prompt = orig_prompt, negative_prompt=neg_prompt)\n",
        "                get_images(embed_2, pipe, filename + \"sense_2_\" + str(i)+\"_neg\", prompt = orig_prompt, negative_prompt=neg_prompt)\n",
        "                get_images(orig_embed, pipe, filename + \"amb_\" + str(i)+\"_neg\", prompt = orig_prompt, negative_prompt=neg_prompt)"
      ],
      "metadata": {
        "id": "sofKVKNQXCD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "kOlpYCPncr4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homonym Duplication\n",
        "\n",
        "Note: Homonym duplication is rare in Stable Diffusion, so it may not necessarily occur in any of the generated images"
      ],
      "metadata": {
        "id": "NczXdgEhV19J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    get_images(one_prompt_embed(\"a woman with a silk bow and arrow\", pipe), pipe, \"homonym_duplication/dup_bow_\"+str(i))"
      ],
      "metadata": {
        "id": "OTgRJtSSPPDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    get_images(one_prompt_embed(\"tall cranes by the ocean\",pipe), pipe, \"homonym_duplication/dup_crane_\"+str(i))"
      ],
      "metadata": {
        "id": "XG3tNbP4TJ7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    get_images(one_prompt_embed(\"a crane by the ocean\",pipe), pipe, \"homonym_duplication/dup_crane_sea_\"+str(i))"
      ],
      "metadata": {
        "id": "oAOzAqJwzrOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    get_images(one_prompt_embed(\"a bat and a baseball fly through the air\",pipe), pipe, \"homonym_duplication/neg_dup_bat_\"+str(i),prompt=\"a bat and a baseball fly through the air\", negative_prompt=\"disfigured, deformed, bad anatomy, low quality, jpeg artifacts\")"
      ],
      "metadata": {
        "id": "Gjj1iIjjZ_fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    get_images(one_prompt_embed(\"a man with glasses\",pipe), pipe, \"homonym_duplication/dup_glasses_\"+str(i))"
      ],
      "metadata": {
        "id": "AzXygLn4z5ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    get_images(one_prompt_embed(\"a gentleman with a bow and arrow\",pipe), pipe, \"homonym_duplication/dup_bow_gent_\"+str(i))"
      ],
      "metadata": {
        "id": "LU1i5fgK-a5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    get_images(one_prompt_embed(\"a baseball bat inside a spooky cave\",pipe), pipe, \"homonym_duplication/dup_bat_cave_\"+str(i))"
      ],
      "metadata": {
        "id": "Nrqq9eraDW7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summing Encodings"
      ],
      "metadata": {
        "id": "8bd3RyL4c1ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concept_sum(\"tree\", \"cat\", pipe, \"meaning_sum/treecat\")\n",
        "concept_sum(\"a wall painted red\", \"a wall painted blue\", pipe, \"meaning_sum/redbluewall\")\n",
        "concept_sum(\"a completely black cat\", \"a completely white cat\", pipe, \"meaning_sum/blackwhitecat\")\n",
        "concept_sum(\"dog\", \"lake\", pipe, \"meaning_sum/doglake\", [0.5, 0.5])\n",
        "concept_sum(\"bear\", \"waterfall\", pipe, \"meaning_sum/bearwaterfall\", [0.5, 0.5])\n",
        "concept_sum(\"bear\", \"hat\", pipe, \"meaning_sum/bearhat\", [0.5, 0.5])\n",
        "concept_sum(\"elephant\", \"snow\", pipe, \"meaning_sum/elephantsnow\", [0.5, 0.5])\n",
        "concept_sum(\"giraffe\", \"beach\", pipe, \"meaning_sum/giraffebeach\", [0.5, 0.5])\n",
        "concept_sum(\"goat\", \"crown\", pipe, \"meaning_sum/goatcrown\", [0.5, 0.5])\n",
        "concept_sum(\"tiger\", \"glasses\", pipe, \"meaning_sum/tigerglasses\", [0.5, 0.5])\n",
        "concept_sum(\"snow\", \"church\", pipe, \"meaning_sum/snowchurch\", [0.5, 0.5])"
      ],
      "metadata": {
        "id": "UDYDVmR91PqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Editing Meaning"
      ],
      "metadata": {
        "id": "eUMfFlEneKWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crane_sentence_animal = [\"a sandhill crane\", \"there is a sandhill crane\", \n",
        "                    \"there is a sandhill crane on the nature reserve\", \n",
        "                    \"a sandhill crane hunts fish\", \n",
        "                    \"a boy feeds a sandhill crane\", \n",
        "                    \"a sandhill crane beside a nest\", \n",
        "                    \"a sandhill crane is eating some fish\", \n",
        "                    \"a sandhill crane in a nest\"]\n",
        "\n",
        "crane_sentence_construction = [\"a tower crane\", \"there is a tower crane\", \n",
        "                    \"there is a tower crane on the building site\", \n",
        "                    \"a tower crane lifts loads\", \n",
        "                    \"a man operates a tower crane\", \n",
        "                    \"a tower crane beside a bulldozer\", \n",
        "                    \"a tower crane is lifting a container\", \n",
        "                    \"a tower crane in a quarry\"]\n",
        "\n",
        "crane_sentence_amb = [\"a crane\", \"there is a crane\", \n",
        "                    \"there is a crane on the other side\", \n",
        "                    \"a crane is tall\", \n",
        "                    \"a boy sees a crane\", \n",
        "                    \"a crane beside a tree\", \n",
        "                    \"a crane is casting a shadow\", \n",
        "                    \"a crane by the ocean\"]\n",
        "\n",
        "bat_sentence_baseball = [\"a baseball bat\", \"there is a baseball bat\", \n",
        "                     \"i play baseball with the baseball bat\", \n",
        "                     \"the boy bought a baseball bat\", \n",
        "                     \"a baseball player swings a baseball bat\", \n",
        "                     \"a baseball bat is laying on the base\", \n",
        "                     \"a baseball bat in a store\",\n",
        "                     \"a sports store sells a baseball bat\"]\n",
        "\n",
        "bat_sentence_animal = [\"a fruit bat\", \"there is a fruit bat\", \n",
        "                    \"i feed insects to the fruit bat\", \n",
        "                    \"the boy saw a fruit bat\", \n",
        "                    \"a wildlife expert feeds a fruit bat\", \n",
        "                    \"a fruit bat is hanging from the tree\", \n",
        "                    \"a fruit bat in a cave\",\n",
        "                    \"a local zoo keeps an fruit bat\"]\n",
        "\n",
        "bat_sentence_amb = [\"a bat\",\"there is a bat\", \"i do things with the bat\", \n",
        "                \"the person saw a bat\",\n",
        "                \"a person mentions a bat\",\n",
        "                \"a bat is laying on the floor\",\n",
        "                \"a bat in a box\",\n",
        "                \"a nearby location has a bat\"]\n",
        "\n",
        "bass_sentence_music = [\"a double bass\",\"there is a double bass\", \n",
        "                \"the musician played a double bass\",\n",
        "                \"a musician plays a double bass\",\n",
        "                \"a jazz band has a double bass\"]\n",
        "\n",
        "bass_sentence_fish = [\"a sea bass\",\"there is a sea bass\", \n",
        "                \"the fisherman caught a sea bass\",\n",
        "                \"an angler holds a sea bass\",\n",
        "                \"a local aquarium has a sea bass\"]\n",
        "\n",
        "bass_sentence_amb = [\"a bass\",\"there is a bass\", \n",
        "                \"the person saw a bass\",\n",
        "                \"a person mentions a bass\",\n",
        "                \"a nearby location has a bass\"]\n",
        "\n",
        "trunk_sentence_box = [\"a storage trunk\",\"there is a storage trunk\",\n",
        "                \"the traveller carried a storage trunk\",\n",
        "                \"a passenger carries a storage trunk\",\n",
        "                \"a storage trunk is being packed\"]\n",
        "\n",
        "trunk_sentence_elephant = [\"an elephant's trunk\",\"there is an elephant's trunk\",\n",
        "                \"the zookeeper touched an elephant's trunk\",\n",
        "                \"an elephant uses a long trunk\",\n",
        "                \"an elephant's trunk is being swung\"]\n",
        "\n",
        "trunk_sentence_amb = [\"a trunk\",\"there is a trunk\",\n",
        "                \"the person saw a trunk\",\n",
        "                \"a person mentions a trunk\",\n",
        "                \"a trunk is being used\"]\n",
        "\n",
        "trunk_sentence_tree = [\"a tree trunk\",\"there is a tree trunk\",\n",
        "                \"the lumberjack sawed a tree trunk\",\n",
        "                \"a carpenter uses a tree trunk\",\n",
        "                \"a tree trunk is being felled\"]\n",
        "\n",
        "glasses_sentence_drink = [\"wine glasses\",\"there are wine glasses\",\n",
        "                \"the waiter filled wine glasses\",\n",
        "                \"a waiter fills wine glasses\",\n",
        "                \"wine glasses are being cleaned\"]\n",
        "\n",
        "glasses_sentence_eyes = [\"reading glasses\",\"there are reading glasses\",\n",
        "                \"the scientist wore reading glasses\",\n",
        "                \"a scientist wears reading glasses\",\n",
        "                \"reading glasses are being cleaned\"]\n",
        "\n",
        "glasses_sentence_amb = [\"glasses\",\"there are glasses\",\n",
        "                \"the person saw glasses\",\n",
        "                \"a person holds glasses\",\n",
        "                \"glasses are being used\"]\n",
        "\n",
        "seal_sentence_wax = [\"a wax seal\",\"there is a wax seal\",\n",
        "                \"the postmaster stamped a wax seal\",\n",
        "                \"a butler opens a wax seal\",\n",
        "                \"a wax seal on an envelope\",\n",
        "                \"a fancy letter has a wax seal\"]\n",
        "\n",
        "seal_sentence_animal = [\"a harp seal\",\"there is a harp seal\",\n",
        "                \"the zookeeper fed a harp seal\",\n",
        "                \"a boy pets a harp seal\",\n",
        "                \"a harp seal in the ocean\",\n",
        "                \"a large zoo has a harp seal\"]\n",
        "\n",
        "seal_sentence_amb = [\"a seal\",\"there is a seal\",\n",
        "                \"the person saw a seal\",\n",
        "                \"a person mentions a seal\",\n",
        "                \"a seal in a frame\",\n",
        "                \"a nearby location has a seal\"]"
      ],
      "metadata": {
        "id": "QUeFxXg6qT0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edit_prompts(\"bass\", {\"a bass\":\"meaning_edit/bass_\",\"a man holding a bass\":\"meaning_edit/bass_man_\", \"a bass displayed on a wall\":\"meaning_edit/bass_wall_\"}, bass_sentence_music, bass_sentence_fish, bass_sentence_amb, pipe, neg_prompt=\"disfigured, deformed, bad anatomy, low quality, jpeg artifacts\", repeat=5)"
      ],
      "metadata": {
        "id": "VnJhp2x7qdSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edit_prompts(\"bat\", {\"a bat\":\"meaning_edit/bat_\", \"a bat and a baseball fly through the air\":\"meaning_edit/bat_fly_through_the_air_\", \"a boy holds a black bat\":\"meaning_edit/bat_boy_\", \"a bat laying on the grass\":\"meaning_edit/bat_grass_\"}, bat_sentence_baseball, bat_sentence_animal, bat_sentence_amb, pipe, neg_prompt=\"disfigured, deformed, bad anatomy, low quality, jpeg artifacts\", repeat=5)"
      ],
      "metadata": {
        "id": "OFZX7Wofqf-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edit_prompts(\"crane\", {\"a crane\":\"meaning_edit/crane_\", \"a crane by the ocean\":\"meaning_edit/crane_by_ocean_\",\"a crane surrounded by nature\":\"meaning_edit/crane_nature_\"}, crane_sentence_construction, crane_sentence_animal, crane_sentence_amb, pipe, neg_prompt=\"disfigured, deformed, bad anatomy, low quality, jpeg artifacts\", repeat=5)"
      ],
      "metadata": {
        "id": "yOwL7omhqkDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edit_prompts(\"glasses\", {\"glasses on a table\":\"meaning_edit/glasses_table_\"}, glasses_sentence_drink, glasses_sentence_eyes, glasses_sentence_amb, pipe, neg_prompt=\"disfigured, deformed, bad anatomy, low quality, jpeg artifacts\", repeat=5)"
      ],
      "metadata": {
        "id": "j6rx0QTHqohD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edit_prompts(\"seal\", {\"a seal\":\"meaning_edit/seal_\",\"a seal on an envelope\":\"meaning_edit/seal_envelope_\"}, seal_sentence_wax, seal_sentence_animal, seal_sentence_amb, pipe, neg_prompt=\"disfigured, deformed, bad anatomy, low quality, jpeg artifacts\", repeat=5)"
      ],
      "metadata": {
        "id": "Zl3L4KUaqqoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edit_prompts(\"trunk\", {\"a trunk\":\"meaning_edit/trunk_\"}, trunk_sentence_box, trunk_sentence_tree, trunk_sentence_amb, pipe, neg_prompt=\"disfigured, deformed, bad anatomy, low quality, jpeg artifacts\", repeat=5)\n"
      ],
      "metadata": {
        "id": "1rY6c2QJqmU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip Images to Download"
      ],
      "metadata": {
        "id": "GV5-1s3oWgMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r imgs.zip imgs/ "
      ],
      "metadata": {
        "id": "Uj6xUJmWHu_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}